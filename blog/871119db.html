<!DOCTYPE html>
<html>
  <!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  
  <title>lua-resty-mlcache 分析 - Skywalker</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0">
  
  <meta name="keywords" content=betta-cyber, game, betta, shokill>
  
    <meta name="description" content="betta">
  
  
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.02">
  
  
    <link rel="alternate" href="/atom.xml " title="Skywalker" type="application/atom+xml">
  

  

  

  <!-- <link rel="stylesheet" href="../css/style.css"> -->
  
<link rel="stylesheet" href="/css/style.css">

  <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=0&t=n&d=b9cDq33TdEsfGb_DpY--uB2pjskzQ8TK9LaE3yuIYzE&co=ffffff&cmo=ffffff&cmn=ffffff&ct=ffffff'></script>
<meta name="generator" content="Hexo 5.4.1"></head>

  <body>
    <div class="container">
      <header class="header">
  <!-- <div class="blog-title">
    <a href="/" class="logo">Skywalker</a>
    <div class="subtitle"></div>
  </div> -->
  <nav class="navbar">
    <ul class="menu">
      
        <li class="menu-item">
          <a href="/" class="menu-item-link " >Home</a>
        </li>
      
        <li class="menu-item">
          <a href="/blog" class="menu-item-link active" >Blog</a>
        </li>
      
        <li class="menu-item">
          <a href="/ebook" class="menu-item-link " >Ebook</a>
        </li>
      
        <li class="menu-item">
          <a href="/music" class="menu-item-link " >Music</a>
        </li>
      
        <li class="menu-item">
          <a href="/about" class="menu-item-link " >About</a>
        </li>
      
    </ul>
  </nav>
</header>

<article class="post">
  <div class="post-title">
    <h1 class="article-title">lua-resty-mlcache 分析</h1>
  </div>
  <div class="post-content">
    <p>lua-resty-mlcache 用 shared dict 和 lua-resty-lrucache ，实现了多层缓存机制。</p>
<p>mlcache 的架构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">┌─────────────────────────────────────────────────┐</span><br><span class="line">│ Nginx                                           │</span><br><span class="line">│       ┌───────────┐ ┌───────────┐ ┌───────────┐ │</span><br><span class="line">│       │worker     │ │worker     │ │worker     │ │</span><br><span class="line">│ L1    │           │ │           │ │           │ │</span><br><span class="line">│       │ Lua cache │ │ Lua cache │ │ Lua cache │ │</span><br><span class="line">│       └───────────┘ └───────────┘ └───────────┘ │</span><br><span class="line">│             │             │             │       │</span><br><span class="line">│             ▼             ▼             ▼       │</span><br><span class="line">│       ┌───────────────────────────────────────┐ │</span><br><span class="line">│       │                                       │ │</span><br><span class="line">│ L2    │           lua_shared_dict             │ │</span><br><span class="line">│       │                                       │ │</span><br><span class="line">│       └───────────────────────────────────────┘ │</span><br><span class="line">│                           │ mutex               │</span><br><span class="line">│                           ▼                     │</span><br><span class="line">│                  ┌──────────────────┐           │</span><br><span class="line">│                  │     callback     │           │</span><br><span class="line">│                  └────────┬─────────┘           │</span><br><span class="line">└───────────────────────────┼─────────────────────┘</span><br><span class="line">                            │</span><br><span class="line">  L3                        │   I/O fetch</span><br><span class="line">                            ▼</span><br><span class="line"></span><br><span class="line">                   Database, API, DNS, Disk, any I/O...</span><br></pre></td></tr></table></figure>

<p>分为三层：</p>
<p>L1 层是使用 lua-resty-lrucache 的虚拟缓存。提供最快的查找。</p>
<p>L2 层是用的 Nginx 的 lua_shared_dict 内存共享。当 L1 层的 key miss 掉时，从这里获取。</p>
<p>L3 层提供一个自定义函数，有一个 Worker 执行，通过 lua-resty-lock 避免对后端的多次访问。L3 获取的值会被放到 L2 缓存当中。</p>
<p>用来做缓存的组件，shared dict 缓存和 lru 缓存。前者只能缓存字符串对象，缓存的数据有且只有一份，每一个 worker 都可以进行访问，所以常用于 worker 之间的数据通信。后者则可以缓存所有的 Lua 对象，但只能在单个 worker 进程内访问，有多少个 worker，就会有多少份缓存数据。</p>
<h2 id="缓存有两个原则"><a href="#缓存有两个原则" class="headerlink" title="缓存有两个原则"></a>缓存有两个原则</h2><p>一是越靠近用户的请求越好，比如能用本地缓存的就不要发送HTTP请求，能用CDN缓存的就不要打到web服务器，能用nginx缓存的就不要用数据库的缓存。</p>
<p>二是尽量使用本进程和本机的缓存解决，因为跨了进程和机器甚至机房，缓存的网络开销就会非常大，在高并发的时候会非常明显。</p>
<p>我们直接贴一下官方的示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># nginx.conf</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    lua_package_path &quot;/path/to/lua-resty-mlcache/lib/?.lua;;&quot;;</span><br><span class="line">    lua_shared_dict cache_dict 1m;</span><br><span class="line"></span><br><span class="line">    init_by_lua_block &#123;</span><br><span class="line">        local mlcache = require &quot;resty.mlcache&quot;</span><br><span class="line"></span><br><span class="line">        local cache, err = mlcache.new(&quot;my_cache&quot;, &quot;cache_dict&quot;, &#123;</span><br><span class="line">            lru_size = 500,    -- size of the L1 (Lua VM) cache</span><br><span class="line">            ttl      = 3600,   -- 1h ttl for hits</span><br><span class="line">            neg_ttl  = 30,     -- 30s ttl for misses</span><br><span class="line">        &#125;)</span><br><span class="line">        if err then</span><br><span class="line"></span><br><span class="line">        end</span><br><span class="line"></span><br><span class="line">        _G.cache = cache</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 8080;</span><br><span class="line">        location / &#123;</span><br><span class="line">            content_by_lua_block &#123;</span><br><span class="line">                local function callback(username)</span><br><span class="line">                    return db:get_user(username) -- &#123; name = &quot;John Doe&quot;, email = &quot;john@example.com&quot; &#125;</span><br><span class="line">                end</span><br><span class="line"></span><br><span class="line">                local user, err = cache:get(&quot;my_key&quot;, nil, callback, &quot;John Doe&quot;)</span><br><span class="line">                ngx.say(user.username) -- &quot;John Doe&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上的示例很好了描述了整个程序运行的逻辑，在init阶段初始化缓存，然后用_G变量赋予全局变量，在使用阶段cache:get获取指定Key的缓存，缓存未命中就会调用L3，也就是callback方法。</p>
<h2 id="缓存风暴问题"><a href="#缓存风暴问题" class="headerlink" title="缓存风暴问题"></a>缓存风暴问题</h2><p>但这个示例中缺失了lua-resty-lock这个组件的调用，为了防止在L3阶段发现缓存风暴，所以把锁非常有必要。</p>
<p>将局部配置修改如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">lua_shared_dict cache_dict 1m;</span><br><span class="line">lua_shared_dict cache_lock 1m;</span><br><span class="line"></span><br><span class="line">init_by_lua_block &#123;</span><br><span class="line">    local mlcache = require &quot;resty.mlcache&quot;</span><br><span class="line"></span><br><span class="line">    local cache, err = mlcache.new(&quot;my_cache&quot;, &quot;cache_dict&quot;, &#123;</span><br><span class="line">        lru_size = 500,    -- size of the L1 (Lua VM) cache</span><br><span class="line">        ttl      = 3600,   -- 1h ttl for hits</span><br><span class="line">        neg_ttl  = 30,     -- 30s ttl for misses</span><br><span class="line">        shm_locks = &quot;cache_lock&quot;,</span><br><span class="line">        resty_lock_opts = &#123;</span><br><span class="line">            exptime = 10,</span><br><span class="line">            timeout = 5</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    if err then</span><br><span class="line"></span><br><span class="line">    end</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="进程之间通讯问题"><a href="#进程之间通讯问题" class="headerlink" title="进程之间通讯问题"></a>进程之间通讯问题</h2><p>这个问题我们使用lua-resty-worker-events模块解决。</p>
<p>此模块提供了一种向Nginx服务器中的其他工作进程发送事件的方法。通信是通过一个共享的存储区进行的，事件数据将存储在该存储区中。</p>
<p>结合我们之前的缓存使用场景，在一个Worker中的缓存更新之后，要通知其他Worker也同步更新，它就发挥作用了。</p>
<p>我们看以下官方提供的示例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">lua_shared_dict process_events 1m;</span><br><span class="line"></span><br><span class="line">init_worker_by_lua_block &#123;</span><br><span class="line">    local ev = require &quot;resty.worker.events&quot;</span><br><span class="line"></span><br><span class="line">    local handler = function(data, event, source, pid)</span><br><span class="line">        print(&quot;received event; source=&quot;,source,</span><br><span class="line">                &quot;, event=&quot;,event,</span><br><span class="line">                &quot;, data=&quot;, tostring(data),</span><br><span class="line">                &quot;, from process &quot;,pid)</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    ev.register(handler)</span><br><span class="line"></span><br><span class="line">    local ok, err = ev.configure &#123;</span><br><span class="line">        shm = &quot;process_events&quot;, -- defined by &quot;lua_shared_dict&quot;</span><br><span class="line">        timeout = 2,            -- life time of unique event data in shm</span><br><span class="line">        interval = 1,           -- poll interval (seconds)</span><br><span class="line"></span><br><span class="line">        wait_interval = 0.010,  -- wait before retry fetching event data</span><br><span class="line">        wait_max = 0.5,         -- max wait time before discarding event</span><br><span class="line">        shm_retries = 999,      -- retries for shm fragmentation (no memory)</span><br><span class="line">    &#125;</span><br><span class="line">    if not ok then</span><br><span class="line">        ngx.log(ngx.ERR, &quot;failed to start event system: &quot;, err)</span><br><span class="line">        return</span><br><span class="line">    end</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在init_worker_by_lua_block阶段初始化，是因为它需要在每个Worker中都运行，便于同步到其他进程，其他的就是一些配置参数问题。</p>
<p>下面我们把它结合上面的缓存模块一起使用。</p>
<p>lua-resty-mlcache提供了ipc接口来支持lua-resty-worker-events模块，我们直接配置参数即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">lua_shared_dict cache_dict    1m;</span><br><span class="line">lua_shared_dict cache_lock    1m;</span><br><span class="line">lua_shared_dict worker_events 1m;</span><br><span class="line"></span><br><span class="line">init_worker_by_lua_block &#123;</span><br><span class="line">    local mlcache = require &quot;resty.mlcache&quot;</span><br><span class="line">    local worker_events = require &quot;resty.worker.events&quot;</span><br><span class="line"></span><br><span class="line">    local ok, err = worker_events.configure &#123;</span><br><span class="line">        shm = &quot;worker_events&quot;, </span><br><span class="line">        timeout = 2,           </span><br><span class="line">        interval = 1,    </span><br><span class="line"></span><br><span class="line">        wait_interval = 0.010, </span><br><span class="line">        wait_max = 0.5,  </span><br><span class="line">        shm_retries = 999,  </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    local cache, err = mlcache.new(&quot;my_cache&quot;, &quot;cache_dict&quot;, &#123;</span><br><span class="line">        lru_size = 500,    -- size of the L1 (Lua VM) cache</span><br><span class="line">        ttl      = 3600,   -- 1h ttl for hits</span><br><span class="line">        neg_ttl  = 30,     -- 30s ttl for misses</span><br><span class="line">        shm_locks = &quot;cache_lock&quot;,</span><br><span class="line">        resty_lock_opts = &#123;</span><br><span class="line">            exptime = 10,</span><br><span class="line">            timeout = 5</span><br><span class="line">        &#125;,</span><br><span class="line">        ipc = &#123;</span><br><span class="line">            register_listeners = function(events)</span><br><span class="line">                for _, event_t in pairs(events) do</span><br><span class="line">                    worker_events.register(</span><br><span class="line">                        function(data)</span><br><span class="line">                            event_t.handler(data)</span><br><span class="line">                        end,</span><br><span class="line">                        channel_name,</span><br><span class="line">                        event_t.channel</span><br><span class="line">                    )</span><br><span class="line">                end</span><br><span class="line">            end,</span><br><span class="line">            broadcast = function(channel, data)</span><br><span class="line">                worker_events.post(channel_name, channel, data)</span><br><span class="line">            end</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">    if err then</span><br><span class="line"></span><br><span class="line">    end</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


  </div>
  <div class="post-footer">
    

    <a href="#top" class="top">↑</a>
  </div>
</article>
<footer>
  &copy; 2023
  <span class="author">
    betta
  </span>
</footer>

    </div>
  </body>
</html>
